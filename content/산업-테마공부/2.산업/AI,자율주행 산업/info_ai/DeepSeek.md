---
title: "DeepSeek"
date: 2025-06-27T02:20:57+09:00
lastmod: 2025-06-27T02:20:57+09:00
type: docs
sidebar:
  open: true
weight: 2
---
<div style="display:none">
  <meta property="article:published_time" content="2025-06-26T17:20:57Z" />
  <meta property="article:modified_time" content="2025-06-26T17:20:57Z" />
</div>
#AI #DeepSeek

[2025-01-25 미국 시황 정리](/daily-summary/2025-01-25-미국-시황-정리/)]], DeepSeek 쇼크
  
	1. [메모리 사용량 및 계산 비용을 앞도적으로 줄인 Gen AI의 등장]한 것임. 
	 - 24.05.17 DeepSeek Ver.2 등장
	 - 24.12.26 DeepSeek Ver.3 557만 달러의 개발비용으로 6710억 개의 매개변수를 가진 대규모 언어 모델 개발 
	 - 25.01.20 DeepSeek R1 추론 모델 Open AI o1 성능 비슷, API 비용이 o1의 5% / 메타 LLaMA의 4%에 불과. 
	
	2. 회사는 미국의 고성능 칩 규제 속 H800 칩 2,000개로 개발했다고 주장하지만, Scale AI CEO인 알렉산더 왕은 "H100 칩 5만 개를 사용했을 가능성"을 주장하며 데이터의 신뢰성 문제를 제기했음. 
	
	3. 그런데, 샘 알트만이 가격 경쟁 심화에 대응하기 위해 o3-mini 모델을 무료로 개방하며 Deekseek의 도전에 응수했으며, 이는 AI 모델 간 가경 경쟁 가속화를 보여주는 사례임.
	
	4. 이러한 [DeepSeek사태를 통해 현재 투입된 빅테크의 Capex 비용에 대한 의구심이 제기되기 시작]했음. 특히 MSFT, AMZN, GOOGL 등은 이미 AI DataCenter 및 R&D에 수백억 달러를 투자해왔으나, [딥시크는 저비용 고효율의 Gen AI를 구축]한 것임. 
	
	5. 더군다나 [트럼프 집권과 동시에 발표된 스타게이트는 향후 4년 간 5,000억 달러 투자 계획을 발표했기에 더욱 민감하게 반응]하고 있음. 
	
	6. DeepSeek는 MoE, FP8, DualPipe, MTP 등의 기술로 이를 달성
	 - MoE(Mixture-of-Experts): 6710억 개의 매개변수 중 필요한 37억 개만 선택적으로 활성화하여 효율성 극대화
	 - FP8 혼합 정밀도 학습: 8비트 부동소수점 연산을 통해 메모리 사용량을 50% 줄이고 학습 속도를 향상
	 - DualPIpe 알고리즘: 데이터 파이프라인을 최적화하여 학습시간을 단축
	 - MTP(다중 토큰 예측): 한 번에 여러 토큰을 생성하여 추론 속도를 3배 이상 향상
	
	7. 물론 여전히 DeepSeek에 대한 여러 문제가 제기되고 있음 
	 - 언어 전환 문제: DeepSeek R1과 R1 Zero 모델은 의도치 않게 다른 언어로 전환
	 - 멀티모달 지원 부족: 이미지나 비디오 입력 처리 불가 
	 - 수익성 지속 가능성: [초저비용 API가 장기적 수익을 저하시킬 가능성]
	
	8. 그러나 이러한 문제들은 향후 해소될 가능성이 크기에 빅테크 업체들 뿐만 아니라, 연결된 인프라 밸류체인 입장에서도 부정적인 뉴스는 맞는 듯 함. 
	
	9. 아직 정확하게 확인할 수 없지만, 결론적으로 이러한 Gen AI를 개발하는 기업들보다는 [이를 활용하는 산업(헬스케어, 금융, 제조업, 정부 등)과 기업에 집중]해야한다고 판단. ![](Pasted%20image%2020250127123720.png)
[2025-01-28 미국 시황 정리](/daily-summary/2025-01-28-미국-시황-정리/)]],  [중국의 DeepSeek이란 무엇이며, 왜 AI 업계를 놀라게 하고 있는가?]

	» DeepSeek은 설립된 지 1년 남짓 된 중국의 AI 스타트업으로, 세계 최고의 챗봇과 비교할 만한 성능을 제공하면서도 비용은 훨씬 저렴한 혁신적인 인공지능 모델을 선보이며 실리콘밸리를 놀라게 하고 있습니다. 
	
	» DeepSeek의 등장은 AI의 미래가 점점 더 많은 전력과 에너지를 필요로 할 것이라는 널리 퍼진 믿음에 반대되는 사례로 주목받고 있습니다. 
	
	» 1월 말, DeepSeek의 혁신에 대한 기대감이 커지며 투자자들이 미국 기반 경쟁업체들과 이들의 하드웨어 공급업체에 미칠 영향을 소화하기 시작하면서 글로벌 기술주가 급락했습니다.

	▪️DeepSeek은 정확히 무엇인가?
	
	» DeepSeek은 2023년 AI 기반 퀀트 헤지펀드인 하이플라이어(High-Flyer)의 대표 량원펑(Liang Wenfeng)에 의해 설립되었습니다. 이 회사는 오픈소스 AI 모델을 개발하며, 이를 통해 개발자 커뮤니티가 소프트웨어를 검토하고 개선할 수 있습니다. DeepSeek의 모바일 앱은 1월 출시 이후 미국 애플의 앱스토어 차트에서 1위를 차지하며 큰 인기를 얻었습니다.
	
	» 이 앱은 OpenAI의 ChatGPT와 같은 다른 챗봇들과 차별화되며, 질문에 대한 응답을 제공하기 전에 추론 과정을 설명하는 방식으로 구별됩니다. DeepSeek은 R1 모델이 OpenAI의 최신 제품과 동등한 성능을 제공한다고 주장하며, 이 기술을 활용해 챗봇을 개발하려는 개인들에게 라이선스를 제공하고 있습니다.

	▪️DeepSeek R1은 OpenAI나 Meta AI와 어떻게 비교되는가?
	
	» DeepSeek의 모델 훈련 및 개발 비용은 OpenAI나 Meta Platforms Inc.의 최고 제품에 비해 훨씬 적은 비용이 드는 것으로 보입니다. 모델의 높은 효율성은 Nvidia와 같은 최신 고성능 AI 가속기를 구매하기 위해 막대한 자본을 투자해야 할 필요성에 의문을 제기합니다. 
	
	» 또한, 이는 첨단 반도체의 대중국 수출 제한에 대한 관심을 더욱 증폭시키고 있습니다. 해당 제한은 DeepSeek과 같은 돌파구를 막기 위해 의도되었으나, DeepSeek의 사례는 이를 무색하게 만들고 있습니다.
	
	» DeepSeek은 R1 모델이 아래의 주요 벤치마크에서 경쟁 모델과 동등하거나 더 나은 성능을 제공한다고 주장합니다.
	• AIME 2024: 수학 문제 해결 능력
	• MMLU: 일반 지식 평가
	• AlpacaEval 2.0: 질문-답변 성능 평가
	• UC 버클리와 연계된 Chatbot Arena 리더보드에서 상위권 기록

	▪️미국에서의 우려는 무엇인가?
	
	» 미국은 GPU 반도체와 같은 첨단 기술의 대중국 수출을 금지하며, AI 기술 발전을 견제하고 있습니다. 그러나 DeepSeek의 발전은 중국 AI 엔지니어들이 제한된 자원 속에서도 효율성을 극대화하며 규제를 피해가고 있음을 보여줍니다. DeepSeek이 첨단 AI 훈련용 하드웨어를 얼마나 많이 활용했는지는 명확하지 않으나, 이 회사의 성과는 미국의 무역 제한이 중국의 발전을 완전히 저지하지 못했음을 의미합니다.

	▪️DeepSeek이 세계적 관심을 끌게 된 시점은 언제인가?
	
	» DeepSeek은 2023년 초기에 모델을 발표한 이후 업계에서 주목받기 시작했습니다. 같은 해 11월, DeepSeek R1 추론 모델이 공개되었는데, 이 모델은 인간 사고를 모방하도록 설계되었습니다. 상기 모델은 모바일 챗봇 앱의 기반이 되었으며, 1월 출시된 웹 인터페이스와 함께 OpenAI보다 훨씬 저렴한 대안으로 세계적인 명성을 얻었습니다. 투자자인 마크 앤드리슨(Marc Andreessen)은 이를 "AI’s Sputnik moment"이라 하였습니다.
	» DeepSeek의 모바일 앱은 1월 25일까지 160만 회 이상 다운로드 되었으며, 호주, 캐나다, 중국, 싱가포르, 미국, 영국의 iPhone 앱 스토어에서 1위를 차지했습니다.

	▪️DeepSeek의 설립자: Liang Wenfeng(량원펑)
	
	• 1985년 중국 광둥성 출생
	• 저장대학교에서 전자 및 정보공학 학사 및 석사 학위를 취득
	• 회사 설립 당시 초기 자본금은 1000만 위안(약 14억 원)
	• 미국의 첨단 칩 접근 제한이 AI 발전의 주요 병목현상이라고 주장
	• 연구진 대부분은 중국의 최고 대학 출신 신입 졸업생들로 구성
	• "더 많은 투자금이 반드시 더 많은 혁신으로 이어지지는 않는다. 그렇지 않다면 대기업이 모든 혁신을 독점했을 것이다."라고 중국 매체 36kr와의 인터뷰에서 발언

	▪️중국 내 AI 생태계에서 DeepSeek의 위치
	
	• 알리바바, 바이두, 텐센트와 같은 중국 대기업들은 AI 하드웨어 및 고객 확보 경쟁을 위해 막대한 자원을 투자해왔습니다.
	• 그러나 DeepSeek은 오픈소스 접근 방식을 채택해 빠르게 많은 사용자를 확보한 뒤, 그 대규모 사용자 기반을 바탕으로 수익화 전략을 개발하고 있습니다.
	• DeepSeek의 저비용 모델은 중국 AI 개발 비용 절감에 기여했으며, 이는 대기업 간 가격 경쟁을 유발하고 있습니다.

	▪️글로벌 AI 시장에 미치는 영향
	
	» DeepSeek의 성공은 OpenAI와 같은 미국 기업들이 기존의 시장 우위를 유지하기 위해 가격을 인하하도록 압박할 가능성이 제기되고 있습니다. 또한, Meta와 Microsoft 같은 대기업들이 AI 인프라에 각각 650억 달러 이상의 자본을 투자한 가운데, DeepSeek의 효율적 모델은 대규모 투자 필요성에 의구심을 만들어내고 있습니다.
	
	» 이러한 영향으로 Nvidia와 ASML 같은 AI 하드웨어 기업들의 주가는 하락했으나, DeepSeek과 연관된 중국 기업(예: Iflytek)의 주가는 상승했습니다. 이미 전 세계 개발자들은 DeepSeek 소프트웨어를 활용해 새로운 툴을 개발하고 있으며, 이는 AI 추론 모델의 채택 속도를 높일 가능성이 있습니다. 동시에, AI 개발에 대한 규제 필요성도 강조되고 있습니다.

	▪️DeepSeek의 단점
	
	1. 중국 내 검열
	» DeepSeek은 1989년 톈안먼 사건, 대만 침공 가능성 등 민감한 주제에 대해 답변을 회피합니다.
	예를 들어, 나렌드라 모디 인도 총리에 대한 자세한 답변은 제공하지만, 시진핑 중국 주석에 대한 답변은 거부합니다.
	
	2. 클라우드 인프라 문제
	» 갑작스러운 인기와 사용량 급증으로 인해 서버 과부하 문제가 발생할 수 있습니다. 실제로, 1월 27일 주요 서비스 장애가 발생하기도 했습니다.

	🤩긴글 한번 읽어주시기 바랍니다.

	DeepSeek와 기존 빅테크 AI의 차이점.
	
	📌DeepSeek Zero : 대규모 강화학습활용하여 처음부터 학습된 모델임.
	
	기존의 감독 학습(SFT)을 사용하지 않았음
	
	강화학습만으로 모델의 추론 능력을 극대화
	
	📌DeepSeek-R1은 초기 Cold Start 데이터를 사용해 SFT를 수행한 후, 
	
	강화학습과 다양한 시나리오의 데이터 학습을 추가로 수행한 모델
	
	우리가 봐야할 것은 강화 학습과 감독 학습의 차이점입니다.
	
	📌강화학습
	1. 에이전트가 환경과 상호작용하며 행동을 선택하고 그 결과로 보상(Reward)을 받음.
	
	2. 학습의 목표는 보상을 최대화하는 최적의 행동 정책을 학습
	
	📌감독 학습
	1. 입력 데이터와 이에 상응하는 정답 레이블이 주어진 상태에서 학습
	
	2. 학습의 목표는 주어진 입력에 대해 올바른 출력을 예측하는 모델을 학습하는 것
	
	DeepSeek는 6700억개의 파라미터중에 단 370억개만 활성화됨.
	
	왜냐? 각 분야마다 그 분야에 필요한 파라미터만 생성하기 때문에 기존 1.8조개의 파라미터 활성화보다 효율적임.
	
	즉, 
	
	📌1. 훈련비용은 낮아지고 
	📌2. 필요한 GPU는 낮아지고
	📌3. 전기 효율도 절감됨.
	
	여기서부터가 중요합니다.
	
	🔥왜  LLM 기반은 AI세계에서 최종 목적지가 아니냐?
	
	우리가 얼마전 CES 2025에서 젠슨황이 얘기한 부분에 대해서 고민해봐야합니다.
	
	📌왜 젠슨황은 갑자기 로보틱스, 물리세계 AI를 말하려고 했을까?
	
	기존 LLM기반의 AI는 이미 상품화가 되어있고 사실 
	
	많은 AI 기업들이 있습니다.
	
	물론 이번 DeepSeek가 Open AI Chat GPT 보다 적은돈으로 많은 부분에서 더 좋은 성과를 거둔 것은 충격적인 이슈입니다.
	
	하지만 현재 AI에서 LLM기반은 최종 목적이 아닙니다.
	
	젠슨황이 말했든 (사진 설명)
	
	📌1단계 : 인식 AI (이미지 인식하고 해석하는 기술)
	
	📌2단계 : 생성 AI (텍스트, 이미지, 비디오 생성 기술) >> 지금의 LLM
	
	📌3단계 : 에이전트 AI (인간과 상호작용 하는 AI ex 콜센터 등등)
	
	📌4단계 : 물리적 AI (자율주행, 로봇 공학)
	
	물리세계 즉, 로보틱스와 자율주행입니다.
	
	따라서 현재 조정중에 우리가 로보틱스와 자율주행에서 얼마만큼 싸움이 일어나고 
	
	누가 승자가 되느냐를 찾아봐야 합니다.
	
	LLM은 작은 싸움이며 자율주행과 로봇이 정말 큰 싸움입니다.
[2025-01-29 미국 시황 정리](2025-01-29%20미국%20시황%20정리.md))), ![](Pasted%20image%2020250128213316.png)DeepSeek가 보여준 최근의 효율성 개선이 추론(adinferencing)의 도입 및 확장 곡선을 앞당기고, 고성능 인공지능(AI) 반도체 솔루션에 대한 수요를 더 빠르게 증가시키는 데 기여할 것이라고 분석했습니다.  
  
  회사는 지난주 출시된 DeepSeek R1 이후, 투자자들이 컴퓨팅 효율성과 관련한 회사의 주장으로 인해 AI 반도체 지출의 중장기적 영향에 대해 우려를 표했다고 전했습니다.  
  
  그러나 클라우드 공급업체 및 하이퍼스케일러들이 더 큰 학습(training) 및 추론 클러스터를 계속 구축함에 따라, Broadcom(AVGO) 및 Marvell(MRVL)과 같은 맞춤형 애플리케이션 전용 집적 회로(ASIC) 공급업체가 비용 및 전력 효율성 측면에서 이점을 누릴 것이라고 애널리스트는 설명했습니다.  
  
  JPMorgan은 "혁신은 멈추지 않으며, 새로운 기회를 촉진한다"며 Broadcom, Marvell, Nvidia에 대한 비중확대(Overweight) 등급을 재확인했습니다.

- 2025-03-08, [중국의 부상: DeepSeek은 확실히 소프트웨어 산업에 큰 호재다.](미래에셋증권_산업_해외산업_20250228094402.pdf#page=15&selection=9,1,25,1&color=yellow)
	- DeepSeek의 기술력은 AI 산업에 큰 변곡점이 되었다. 끝난 줄 알았던 데이터 스케일링 법칙이 DeepSeek의 알고리즘 덕분에 되살아 났기 때문이다. 
	- 우선 DeepSeek이 가져온 변화는 1) 오픈소스 LLM이 계속해서 늘어나 시장을 주도할 것 이라는 점과, 2) 효율성이 확대된 알고리즘으로 비용이 감소할 것이라는 점, 3) 추가적으로 오픈소스 형태의 LLM 확산은 [사이버 보안](/industry-study/사이버-보안/) 시장의 확대와 연결된다는 점이다. LLM의 성장은 어플리케이션의 확대와도 유기적으로 연결될 수 있다. 특히 데이터가 핵심 인 AI 산업 특성상 B2C 시장의 개화가 북미권보다 [중국](/industry-study/4국가중국/)에서 시작될 가능성도 더 높다고 판단한다
	-
